% A schematic diagram showing the shape of the feature map as it passes through the network.

% In the encoding path, the feature map is transformed with two successive 3x3x3 convolutions and ReLU activations
% followed by a 2x2x2 max-pooling operation that reduces the spatial dimensions by half.

% In the decoding path, information from fine and coarse scales is combined through skip connections.
% The feature map is upsampled by a factor of 2 using a 3x3x3 transposed convolution.
% This is combined with the feature map from the contracting path through a skip connection,
% which is passed through an attention gate before being concatenated with the upsampled feature map.
% The feature map from deeper in the network acts as the attention gating signal.
% The upsampled feature map and attended feature map from the skip connection are concatenated and
% convolved along the channel dimension to produce the final feature map.

\documentclass{standalone}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning, calc}

% Styles - blocks
\tikzstyle{block} = [rectangle, draw, text centered, minimum width=2cm, minimum height=1cm, fill=white]
\tikzstyle{attention} = [circle, draw, text centered, minimum size=1cm, fill=orange!20]
\tikzstyle{concatmerge} = [circle, draw, text centered, minimum size=0.05cm, font=\tiny]

% arrows
\tikzstyle{conv} = [thick, ->, >=stealth, black]
\tikzstyle{pool} = [thick, ->, >=stealth, green]
\tikzstyle{up}   = [thick, ->, >=stealth, orange]
\tikzstyle{skip} = [thick, dashed, ->, >=stealth, gray]
\tikzstyle{gate} = [thick, ->, >=stealth, blue]
\tikzstyle{merge} = [thick, ->, >=stealth, red]
\tikzstyle{concat} = [draw, thick, black]


\begin{document}
\begin{tikzpicture}[node distance=1.8cm and 0.5cm]

	% Input image and patch
	\node (input_full) [block, fill=gray!10] {Original Image $1\times192^3$};
	\node (input_patch) [block, below=4cm of input_full, fill=gray!30, align=center] {Extracted Patch\\$1\times160^3$};

	% Encoder
	\node (enc0a) [block, below=2.5cm of input_patch] {$8\times160^3$};
	\node (enc0b) [block, below left=2cm and 1cm of enc0a] {$16\times160^3$};

	\node (enc1a) [block, right=1cm of enc0b] {$16\times80^3$};
	\node (enc1b) [block, below left=2cm and 1cm of enc1a] {$32\times80^3$};

	\node (enc2a) [block, right=1cm of enc1b] {$32\times40^3$};
	\node (enc2b) [block, below left=2cm and 1cm of enc2a] {$64\times40^3$};

	\node (enc3a) [block, right=1cm of enc2b] {$64\times20^3$};
	\node (enc3b) [block, below left=2cm and 1cm of enc3a] {$128\times20^3$};

	\node (enc4a) [block, right=1cm of enc3b] {$128\times10^3$};
	\node (enc4b) [block, below right=3cm and 1cm of enc4a] {$256\times10^3$};

	% Bottleneck
	\node (bottom) [block, right=1cm of enc4b] {$256\times5^3$};
	\node (dec4up) [block, above right=1cm and 0.5cm of bottom]   {$128\times10^3$};

	% Attention Gates
	\node (att4) [attention, right=7cm of enc4a] {$\sigma$};
	\node (merge4) [concatmerge, right=0.5cm of att4] {$+$};
	\node (dec4concat) [block, right=2cm of att4] {$128\times10^3$};

	\node (att3) [attention, right=7cm of enc3a] {$\sigma$};
	\node (dec3concat) [block, right=2cm of att3]   {$64\times20^3$};
	\node (merge3) [concatmerge, right=0.5cm of att3] {$+$};
	\node (dec3up) [block, below=0.5cm of att3] {$64\times20^3$};

	\node (att2) [attention, right=7cm of enc2a] {$\sigma$};
	\node (dec2concat) [block, right=2cm of att2]   {$32\times40^3$};
	\node (merge2) [concatmerge, right=0.5cm of att2] {$+$};
	\node (dec2up) [block, below=0.5cm of att2] {$32\times40^3$};

	\node (att1) [attention, right=7cm of enc1a] {$\sigma$};
	\node (dec1concat) [block, right=2cm of att1]   {$16\times80^3$};
	\node (merge1) [concatmerge, right=0.5cm of att1] {$+$};
	\node (dec1up) [block, below=0.5cm of att1] {$16\times80^3$};

	\node (att0) [attention, right=7cm of enc0a] {$\sigma$};
	\node (dec0concat) [block, right=2cm of att0] {$8\times160^3$};
	\node (merge0) [concatmerge, right=0.5cm of att0] {$+$};
	\node (dec0up) [block, below=0.5cm of att0] {$8\times160^3$};

	\node (output_patch) [block, above=2.5cm of dec0concat, fill=green!20, align=center] {Output\\$1\times160^3$};
	\node (output_full) [block, fill=green!20, above=4cm of output_patch] {Segmentation Mask$1\times192^3$};

	% Arrows for patch extratction
	\draw[thick, bend right=30, dotted, ->] (input_full.south west) to (input_patch.north west);
	\draw[thick, bend right=30, dotted, ->] (output_patch.north east) to (output_full.south east);

	\node (extraction) [below=2cm of input_full, align=center] {Extract patches};
	\node (stitching) [below=2cm of output_full, align=center] {Stitch together patches};

	% Arrows - conv
	\draw[conv] (enc0a.south west) -- (enc0b.north east);
	\draw[conv] (enc1a.south west) -- (enc1b.north east);
	\draw[conv] (enc2a.south west) -- (enc2b.north east);
	\draw[conv] (enc3a.south west) -- (enc3b.north east);
	\draw[conv] (enc4a) -- (enc4b.north west);

	% Arrows - Encoder
	\draw[conv] (input_patch) -- (enc0a);
	\draw[pool] (enc0b) -- (enc1a);
	\draw[pool] (enc1b) -- (enc2a);
	\draw[pool] (enc2b) -- (enc3a);
	\draw[pool] (enc3b) -- (enc4a);
	\draw[pool] (enc4b.east) -- (bottom.west);

	% Skip Connections with Attention
	\draw[skip] (enc4a) -- (att4);
	\draw[skip] (enc3a) -- (att3);
	\draw[skip] (enc2a) -- (att2);
	\draw[skip] (enc1a) -- (att1);
	\draw[skip] (enc0a) -- (att0);

	\draw[skip] (att4) -- (merge4);
	\draw[skip] (att3) -- (merge3);
	\draw[skip] (att2) -- (merge2);
	\draw[skip] (att1) -- (merge1);
	\draw[skip] (att0) -- (merge0);

	% Gating Signals
	\draw[gate] (dec4up) -- (att4);
	\draw[gate] (dec3up) -- (att3);
	\draw[gate] (dec2up) -- (att2);
	\draw[gate] (dec1up) -- (att1);
	\draw[gate] (dec0up) -- (att0);

	% Concatenation
	\draw[concat] (dec4up.north) -- (merge4);
	\draw[concat] (dec3up.north) -- (merge3);
	\draw[concat] (dec2up.north) -- (merge2);
	\draw[concat] (dec1up.north) -- (merge1);
	\draw[concat] (dec0up.north) -- (merge0);

	% Merge convolutions
	\draw[merge] (merge4) -- (dec4concat);
	\draw[merge] (merge3) -- (dec3concat);
	\draw[merge] (merge2) -- (dec2concat);
	\draw[merge] (merge1) -- (dec1concat);
	\draw[merge] (merge0) -- (dec0concat);

	% Up Sampling
	\draw[up] (bottom.north east) -- (dec4up.south);
	\draw[up] (dec4concat.north west) -- (dec3up.south east);
	\draw[up] (dec3concat.north west) -- (dec2up.south east);
	\draw[up] (dec2concat.north west) -- (dec1up.south east);
	\draw[up] (dec1concat.north west) -- (dec0up.south east);

	\draw[merge] (dec0concat) -- (output_patch);

	% Legend
	\matrix[draw, above right=-3cm and 1cm of input_patch,
		column sep=0.6cm, row sep=0.4cm,
	] {

		% Arrow examples
		\node {\begin{tikzpicture}[baseline]
				\draw[conv] (0,0) -- (0.6,0);
			\end{tikzpicture}}; & \node[align=left, text width=4cm] {(Conv3D + ReLU) $\times2$};  \\

		\node {\begin{tikzpicture}[baseline]
				\draw[pool] (0,0) -- (0.6,0);
			\end{tikzpicture}}; & \node[align=left, text width=4cm] {Max Pooling};  \\

		\node {\begin{tikzpicture}[baseline]
				\draw[up] (0,0) -- (0.6,0);
			\end{tikzpicture}}; & \node[align=left, text width=4cm] {Transposed Conv};  \\

		\node {\begin{tikzpicture}[baseline]
				\draw[skip] (0,0) -- (0.6,0);
			\end{tikzpicture}}; & \node[align=left, text width=4cm] {Skip Connection};  \\

		\node {\begin{tikzpicture}[baseline]
				\draw[gate] (0,0) -- (0.6,0);
			\end{tikzpicture}}; & \node[align=left, text width=4cm] {Gating Signal};  \\

		\node {\begin{tikzpicture}[baseline]
				\draw[merge] (0,0) -- (0.6,0);
			\end{tikzpicture}}; & \node[align=left, text width=4cm] {Convolution};  \\

		\node[attention] {$\sigma$}; & \node[align=left, text width=4cm] {Attention Gate};  \\
		\node[concatmerge] {+}; & \node[align=left, text width=4cm] {Concatenation}; \\
	};

\end{tikzpicture}
\end{document}
