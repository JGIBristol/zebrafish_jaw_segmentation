{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb27ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fishjaw.util import util\n",
    "\n",
    "config = util.userconf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read in a small number of CT scans and the corresponding labels\"\"\"\n",
    "\n",
    "import pathlib\n",
    "\n",
    "\n",
    "dicom_dir = pathlib.Path(\"../../dicoms/Training set 2/\")\n",
    "dicom_paths = sorted(list(dicom_dir.glob(\"*.dcm\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08766533",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_paths = dicom_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d251bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from fishjaw.images import io\n",
    "\n",
    "imgs, labels = zip(*[io.read_dicom(path) for path in tqdm(dicom_paths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import center_of_mass\n",
    "\n",
    "centroids = [tuple(map(int, center_of_mass(label))) for label in tqdm(labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot the centroids\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "for img, label, centroid, axis in zip(imgs, labels, centroids, axes):\n",
    "    img_slice = img[centroid[0]]\n",
    "    label_slice = label[centroid[0]]\n",
    "\n",
    "    axis.imshow(img_slice, cmap=\"gray\", vmin=0, vmax=255**2)\n",
    "    axis.imshow(label_slice, cmap=\"afmhot_r\", alpha=0.3)\n",
    "\n",
    "    axis.scatter(centroid[2], centroid[1], color=\"red\", s=20, label=\"Centroid\")\n",
    "    axis.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we don't really need all the information of the high-resolution images,\n",
    "# we can downsample them to speed up processing.\n",
    "\n",
    "# ndimage.zoom is faster but i think skimage.resize is more accurate\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "scale_factors = []\n",
    "resized_imgs = []\n",
    "resized_labels = []\n",
    "scaled_centroids = []\n",
    "\n",
    "output_size = (128, 128, 128)\n",
    "for img, label, centroid in tqdm(\n",
    "    zip(imgs, labels, centroids, strict=True), total=len(imgs)\n",
    "):\n",
    "    assert img.shape == label.shape, \"Image and label must have the same shape\"\n",
    "\n",
    "    # Calculate scale factors for each dimension\n",
    "    scale_factor = tuple(\n",
    "        target_dim / orig_dim for orig_dim, target_dim in zip(img.shape, output_size)\n",
    "    )\n",
    "    scale_factors.append(scale_factor)\n",
    "\n",
    "    # Resize image and label using zoom\n",
    "    resized_img = zoom(img, scale_factor, order=3)  # Use cubic interpolation for images\n",
    "    resized_label = zoom(\n",
    "        label, scale_factor, order=0\n",
    "    )  # Use nearest-neighbor for labels\n",
    "\n",
    "    resized_imgs.append(resized_img)\n",
    "    resized_labels.append(resized_label)\n",
    "\n",
    "    # Rescale centroid to match the resized image\n",
    "    scaled_centroid = tuple(int(c * sf) for c, sf in zip(centroid, scale_factor))\n",
    "    scaled_centroids.append(scaled_centroid)\n",
    "\n",
    "print(\"Scale factors:\", scale_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "for img, label, centroid, axis in zip(\n",
    "    resized_imgs, resized_labels, scaled_centroids, axes\n",
    "):\n",
    "    img_slice = img[centroid[0]]\n",
    "    label_slice = label[centroid[0]]\n",
    "\n",
    "    axis.imshow(img_slice, cmap=\"gray\")\n",
    "    axis.imshow(label_slice, cmap=\"afmhot_r\", alpha=0.3)\n",
    "\n",
    "    axis.scatter(centroid[2], centroid[1], color=\"red\", s=20, label=\"Centroid\")\n",
    "    axis.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model arch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Simple3DCNNRegressor(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super(Simple3DCNNRegressor, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "        )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(), nn.Linear(64, 128), nn.ReLU(), nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.regressor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, images, centroids):\n",
    "        self.data = (\n",
    "            torch.tensor(np.array(images, dtype=np.float32), dtype=torch.float32)\n",
    "            .unsqueeze(1)\n",
    "            .to(\"cuda\")\n",
    "        )\n",
    "        self.centroids = torch.tensor(np.array(centroids), dtype=torch.float32).to(\n",
    "            \"cuda\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.centroids[idx]\n",
    "\n",
    "\n",
    "# Initialize\n",
    "model = Simple3DCNNRegressor().to(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_dataset = ImgDataset(resized_imgs, scaled_centroids)\n",
    "val_dataset = ImgDataset(resized_imgs, scaled_centroids)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a65748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, train_data, val_data):\n",
    "    model.train()\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    pbar = tqdm(range(25), total=25, desc=\"Training Epochs\")\n",
    "    for epoch in pbar:\n",
    "        train_loss, val_loss = [], []\n",
    "\n",
    "        for i, (volumes, coords) in enumerate(train_data):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(volumes)\n",
    "            loss = criterion(outputs, coords)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        for i, (volumes, coords) in enumerate(val_data):\n",
    "            with torch.no_grad():\n",
    "                outputs = model(volumes)\n",
    "                loss = criterion(outputs, coords)\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        pbar.set_postfix(train_loss=np.mean(train_loss), val_loss=np.mean(val_loss))\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "train_losses, val_losses = train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ae18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fishjaw.visualisation import training\n",
    "\n",
    "fig = training.plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model - perform some cropping\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_volume, test_coords = dataset[0]\n",
    "    test_volume = test_volume.unsqueeze(0).to(\"cuda\")\n",
    "    predicted_coords = model(test_volume)\n",
    "    predicted_coords = predicted_coords.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "print(f\"train data: Predicted {predicted_coords}, True: {test_coords.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f12cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot slices of the cropped jaw\n",
    "fig, axis = plt.subplots(1, 1)\n",
    "\n",
    "img_slice = resized_imgs[0][int(predicted_coords[0])]\n",
    "label_slice = resized_labels[0][int(predicted_coords[0])]\n",
    "\n",
    "axis.imshow(img_slice, cmap=\"gray\")\n",
    "axis.imshow(label_slice, cmap=\"afmhot_r\", alpha=0.3)\n",
    "axis.scatter(\n",
    "    predicted_coords[2],\n",
    "    predicted_coords[1],\n",
    "    color=\"red\",\n",
    "    s=20,\n",
    "    label=\"Predicted Centroid\",\n",
    ")\n",
    "axis.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish_jaw_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
