{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fcd37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features_df = pd.read_csv(\"features.csv\", index_col=0)\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add a column describing the mutation status (wt/het/hom/mosaic)\n",
    "\"\"\"\n",
    "\n",
    "from fishjaw.inference import feature_selection\n",
    "\n",
    "features_df = feature_selection.add_metadata_cols(features_df)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d00f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remove features with zero variance\n",
    "\"\"\"\n",
    "\n",
    "null_variance_cols = features_df[\"Features\"].columns[features_df[\"Features\"].var() == 0]\n",
    "features_df.drop(columns=null_variance_cols, inplace=True, level=1)\n",
    "\n",
    "print(f\"Dropped:\\n\\t\", \", \".join(null_variance_cols))\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc727d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot correlations\n",
    "\"\"\"\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = features_df[\"Features\"].corr()\n",
    "sns.heatmap(corr, vmin=-1, vmax=1, cmap=\"seismic\")\n",
    "\n",
    "c = np.abs(corr.to_numpy().flat)\n",
    "c[c == 1.0] = np.nan\n",
    "\n",
    "fig, axis = plt.subplots()\n",
    "axis.hist(c, bins=100)\n",
    "axis.set_title(r\"$\\left|\\mathrm{Correlations}\\right|$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Drop highly correlated features\n",
    "\"\"\"\n",
    "\n",
    "from typing import Iterable, Tuple, List, Optional\n",
    "\n",
    "\n",
    "def drop_correlated_features(\n",
    "    df: pd.DataFrame,\n",
    "    threshold: float = 0.8,\n",
    "    protected: Optional[Iterable[str]] = None,\n",
    "    prefer: str = \"lower_variance\",  # or \"higher_variance\" or \"mean_corr\"\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Greedily drop a minimal-ish set of columns so that all remaining\n",
    "    pairwise absolute correlations are <= threshold.\n",
    "\n",
    "    - protected: columns never to drop (will raise if impossible).\n",
    "    - prefer: tie-breaker when choosing what to drop among highly connected nodes.\n",
    "    \"\"\"\n",
    "    if not 0 <= threshold <= 1:\n",
    "        raise ValueError(\"threshold must be in [0, 1]\")\n",
    "\n",
    "    prot = set(protected or [])\n",
    "\n",
    "    # Absolute correlation matrix\n",
    "    corr = df.corr().abs()\n",
    "    # Remove self-correlation to simplify logic\n",
    "    np.fill_diagonal(corr.values, 0.0)\n",
    "    # Replace NaNs with 0 (e.g., constant columns). Ideally drop NaNs beforehand.\n",
    "    corr = corr.fillna(0.0)\n",
    "\n",
    "    to_drop: List[str] = []\n",
    "    remaining = corr.index.tolist()\n",
    "\n",
    "    while True:\n",
    "        # Edges above threshold\n",
    "        mask = corr > threshold\n",
    "        if not mask.values.any():\n",
    "            break\n",
    "\n",
    "        # Degree = number of correlations above threshold\n",
    "        deg = mask.sum(axis=1)\n",
    "\n",
    "        # Candidate nodes with max degree\n",
    "        max_deg = deg.max()\n",
    "        cand = deg[deg == max_deg].index.tolist()\n",
    "\n",
    "        # Apply tie-breaker\n",
    "        if prefer == \"lower_variance\":\n",
    "            var = df[cand].var(numeric_only=True)\n",
    "            pick = var.idxmin()\n",
    "        elif prefer == \"higher_variance\":\n",
    "            var = df[cand].var(numeric_only=True)\n",
    "            pick = var.idxmax()\n",
    "        elif prefer == \"mean_corr\":\n",
    "            mc = corr.loc[cand].mean(axis=1)\n",
    "            pick = mc.idxmax()\n",
    "        else:\n",
    "            pick = cand[0]  # deterministic order if possible\n",
    "\n",
    "        if pick in prot:\n",
    "            # If protected is involved in edges, try dropping the most offending non-protected neighbor\n",
    "            # Choose neighbor with largest correlation to the protected node\n",
    "            neighbors = corr.columns[mask.loc[pick]]\n",
    "            neighbors = [n for n in neighbors if n not in prot]\n",
    "            if not neighbors:\n",
    "                raise RuntimeError(\n",
    "                    f\"Cannot satisfy threshold={threshold} without dropping protected feature '{pick}'\"\n",
    "                )\n",
    "            # Choose neighbor with highest correlation to the protected pick\n",
    "            pick = corr.loc[pick, neighbors].idxmax()\n",
    "\n",
    "        # Drop the picked column/row from the working correlation matrix\n",
    "        to_drop.append(pick)\n",
    "        corr = corr.drop(index=pick, columns=pick)\n",
    "        remaining.remove(pick)\n",
    "\n",
    "    return remaining, to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787cd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept, dropped = drop_correlated_features(features_df[\"Features\"], threshold=0.8)\n",
    "# Keep only 'kept'\n",
    "features_df.drop(columns=dropped, level=1, inplace=True)\n",
    "print(f\"Dropped {len(dropped)} cols:\\n\\t\", \", \".join(dropped))\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = features_df[\"Features\"].corr()\n",
    "sns.heatmap(corr, vmin=-1, vmax=1, cmap=\"seismic\")\n",
    "\n",
    "c = np.abs(corr.to_numpy().flat)\n",
    "c[c == 1.0] = np.nan\n",
    "\n",
    "fig, axis = plt.subplots()\n",
    "axis.hist(c, bins=100)\n",
    "axis.set_title(r\"$\\left|\\mathrm{Correlations}\\right|$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a6cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = features_df[\"Features\"]\n",
    "mu = X.mean()\n",
    "sigma = X.std(ddof=0)\n",
    "\n",
    "features_df[\"Features\"] = (X - mu) / sigma.replace(0.0, np.nan)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee16a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Mann-Whitney U\"\"\"\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "def feature_tests(df):\n",
    "    X = df[\"Features\"]\n",
    "    y = df[(\"Metadata\", \"genotype\")]\n",
    "    results = []\n",
    "    for col in X.columns:\n",
    "        group1 = X.loc[y == \"wt\", col]  # WT\n",
    "        group2 = X.loc[y != \"wt\", col]  # mutant\n",
    "        stat, p = mannwhitneyu(group1, group2, alternative=\"two-sided\")\n",
    "        auc = np.mean(\n",
    "            [val > group2.median() for val in group1]\n",
    "        )  # quick effect size proxy\n",
    "        results.append((col, stat, p, auc))\n",
    "    df = pd.DataFrame(results, columns=[\"feature\", \"U\", \"pval\", \"effect_size\"])\n",
    "    df[\"pval_adj\"] = multipletests(df.pval, method=\"fdr_bh\")[1]\n",
    "    return df.sort_values(\"pval_adj\")\n",
    "\n",
    "\n",
    "results = feature_tests(features_df)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb9075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=0)\n",
    "rf.fit(features_df[\"Features\"], features_df[(\"Metadata\", \"genotype\")])\n",
    "importances = pd.Series(rf.feature_importances_, index=features_df[\"Features\"].columns)\n",
    "print(importances.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distributions of the top three mann whitney score variables\n",
    "X = features_df[\"Features\"]\n",
    "y = features_df[(\"Metadata\", \"genotype\")]\n",
    "y = y.rename(\"genotype\")\n",
    "\n",
    "# Long form for FacetGrid\n",
    "df_long = X.assign(genotype=y).melt(\n",
    "    id_vars=\"genotype\", var_name=\"feature\", value_name=\"value\"\n",
    ")\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    df_long,\n",
    "    col=\"feature\",\n",
    "    col_wrap=4,\n",
    "    height=3.0,\n",
    "    sharex=False,\n",
    "    sharey=False,\n",
    "    hue=\"genotype\",\n",
    ")\n",
    "g.map_dataframe(sns.kdeplot, x=\"value\", common_norm=False)\n",
    "g.add_legend()\n",
    "g.set_titles(\"{col_name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(features_df, hue=(\"Metadata\", \"genotype\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fad534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example data ---\n",
    "# Replace these with your MWU and RF results\n",
    "# MWU results: columns=['feature', 'pval_adj']\n",
    "# RF importances: series indexed by feature\n",
    "mwu_df = results[[\"feature\", \"pval_adj\"]].copy()\n",
    "rf_importances = importances.copy()  # from your RF series\n",
    "\n",
    "# Merge MWU and RF\n",
    "summary = mwu_df.set_index(\"feature\").join(rf_importances.rename(\"rf_importance\"))\n",
    "summary = summary.fillna(0)  # in case some features missing\n",
    "\n",
    "# Compute -log10 FDR for MWU\n",
    "summary[\"minus_log10_fdr\"] = -np.log10(summary[\"pval_adj\"])\n",
    "\n",
    "# Sort features by MWU significance (or RF importance)\n",
    "summary = summary.sort_values(\"minus_log10_fdr\", ascending=False)\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar plot: MWU significance\n",
    "ax1.bar(summary.index, summary[\"minus_log10_fdr\"], color=\"skyblue\", label=\"-log10(FDR)\")\n",
    "ax1.set_ylabel(\"-log10(FDR) Mann-Whitney U\", color=\"blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "ax1.set_xticklabels(summary.index, rotation=45, ha=\"right\")\n",
    "\n",
    "# Overlay: RF importance as line\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    summary.index,\n",
    "    summary[\"rf_importance\"],\n",
    "    color=\"red\",\n",
    "    marker=\"o\",\n",
    "    label=\"Random Forest importance\",\n",
    ")\n",
    "ax2.set_ylabel(\"RF importance\", color=\"red\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(loc=\"upper right\")\n",
    "ax2.legend(loc=\"right\")\n",
    "\n",
    "plt.title(\"Feature importance: Mann-Whitney U vs Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PCA and biplot to get an idea of what good descriptors might be\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- Standardize features ---\n",
    "X = features_df[\"Features\"].copy()\n",
    "y = (features_df[(\"Metadata\", \"genotype\")] == \"wt\").copy()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- Run PCA ---\n",
    "pca = PCA(n_components=2)  # first two PCs for biplot\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# --- Explained variance ---\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "print(f\"PC1 explains {explained_var[0]*100:.1f}% of variance\")\n",
    "print(f\"PC2 explains {explained_var[1]*100:.1f}% of variance\")\n",
    "\n",
    "# --- Biplot ---\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot of samples\n",
    "colors = [\"blue\" if label == 0 else \"red\" for label in y]\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=colors, alpha=0.6)\n",
    "plt.xlabel(f\"PC1 ({explained_var[0]*100:.1f}%)\")\n",
    "plt.ylabel(f\"PC2 ({explained_var[1]*100:.1f}%)\")\n",
    "\n",
    "# Plot feature vectors (loadings)\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "for i, feature in enumerate(X.columns):\n",
    "    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], color=\"black\", alpha=0.7)\n",
    "    plt.text(loadings[i, 0] * 1.15, loadings[i, 1] * 1.15, feature, fontsize=9)\n",
    "\n",
    "plt.title(\"PCA Biplot of Radiomics Features\")\n",
    "plt.grid(True)\n",
    "plt.axhline(0, color=\"grey\", linewidth=0.8)\n",
    "plt.axvline(0, color=\"grey\", linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Optional: Plot feature importance from PCA (absolute loadings) ---\n",
    "feature_importance = pd.Series(\n",
    "    np.abs(pca.components_[0]) + np.abs(pca.components_[1]), index=X.columns\n",
    ")\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "feature_importance.plot(kind=\"bar\", color=\"purple\")\n",
    "plt.ylabel(\"Sum of absolute loadings (PC1 + PC2)\")\n",
    "plt.title(\"Feature contribution to first two principal components\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    index=features_df[\"Features\"].columns,\n",
    "    columns=[f\"PC{i+1}\" for i in range(pca.n_components_)],\n",
    ")\n",
    "\n",
    "# --- Plot top features per PC ---\n",
    "num_top_features = 10  # number of top contributing features to show per PC\n",
    "num_pcs_to_plot = 2  # how many PCs to visualize\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    num_pcs_to_plot, 1, figsize=(10, 3 * num_pcs_to_plot), sharex=True\n",
    ")\n",
    "\n",
    "for i in range(num_pcs_to_plot):\n",
    "    pc = f\"PC{i+1}\"\n",
    "    # Get absolute loadings sorted\n",
    "    sorted_loadings = loadings[pc].abs().sort_values(ascending=False)\n",
    "    top_features = sorted_loadings.head(num_top_features)\n",
    "\n",
    "    # Barplot\n",
    "    axes[i].bar(top_features.index, top_features.values, color=\"teal\")\n",
    "    axes[i].set_ylabel(f\"{pc} |loading|\")\n",
    "    axes[i].set_title(f\"Top {num_top_features} features contributing to {pc}\")\n",
    "    axes[i].set_xticklabels(labels=top_features.index, rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fishjaw (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
