{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add the zebrafish jaw lib to python path\n",
    "\"\"\"\n",
    "\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"\"), \"..\", \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30bdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The first thing we'll do is read a model from disk - we want to access its config file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from fishjaw.model import model\n",
    "\n",
    "jaw_model = model.load_model(\"attempt_3.pkl\")\n",
    "jaw_config = jaw_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We'll fine tune on some quadrates that Wahab segmented - we'll want to read these from the RDSF and crop to the right region of interest\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import pathlib\n",
    "\n",
    "import tifffile\n",
    "from tqdm import tqdm\n",
    "\n",
    "wahab_labels = (\n",
    "    jaw_config[\"rdsf_dir\"]\n",
    "    / pathlib.Path(\"1Felix and Rich make models/Training dataset Tiffs/Training set 1\")\n",
    ").glob(\"*.tif\")\n",
    "\n",
    "# Remove these ones, since the 3D tifs dont exist\n",
    "bad_labels = re.compile(r\"(351|401|420|441)\")\n",
    "wahab_labels = [label for label in wahab_labels if not bad_labels.search(label.name)]\n",
    "\n",
    "# Read the labels\n",
    "quadrate_labels = [tifffile.imread(path) for path in tqdm(wahab_labels)]\n",
    "quadrate_labels = [(l == 4) | (l == 5) for l in tqdm(quadrate_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in the images\n",
    "\"\"\"\n",
    "\n",
    "from fishjaw.util import files\n",
    "\n",
    "img_paths = [files.get_3d_tif(label_path) for label_path in wahab_labels]\n",
    "for p in img_paths:\n",
    "    assert p.exists()\n",
    "\n",
    "quadrate_imgs = [tifffile.imread(path) for path in tqdm(img_paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the centre of the quadrates and crop the labels and images\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from scipy.ndimage import center_of_mass\n",
    "\n",
    "centroids = [\n",
    "    tuple(round(x) for x in center_of_mass(label)) for label in tqdm(quadrate_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fishjaw.images import transform\n",
    "\n",
    "window_size = transform.window_size(jaw_config)\n",
    "cropped_labels = [transform.crop(l, c, window_size, centred=True) for l, c in zip(tqdm(quadrate_labels), centroids)]\n",
    "cropped_quadrates = [transform.crop(i, c, window_size, centred=True) for i, c in zip(tqdm(quadrate_imgs), centroids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd459fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the jaws and labels just to check\n",
    "\n",
    "\"\"\"\n",
    "from fishjaw.visualisation import images_3d\n",
    "\n",
    "if debug_plots:\n",
    "    for img, label in zip(cropped_quadrates, cropped_labels):\n",
    "        images_3d.plot_slices(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbbfac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a dataloader for these\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torchio as tio\n",
    "from fishjaw.model import data\n",
    "\n",
    "\n",
    "# This is the size of the training data\n",
    "jaw_config[\"batch_size\"] = 11\n",
    "\n",
    "# Because we're in Jupyter\n",
    "jaw_config[\"num_workers\"] = 0\n",
    "\n",
    "# Turn them all into tio subjects first\n",
    "subjects = [\n",
    "    data.imgs2subject(img, label)\n",
    "    for img, label in zip(cropped_quadrates, cropped_labels)\n",
    "]\n",
    "\n",
    "train_subjects = tio.SubjectsDataset(\n",
    "    subjects[:11], transform=data._transforms(jaw_config[\"transforms\"])\n",
    ")\n",
    "val_subjects = tio.SubjectsDataset(\n",
    "    [subjects[-1]], transform=data._transforms(jaw_config[\"transforms\"])\n",
    ")\n",
    "\n",
    "quadrate_data = data.DataConfig(jaw_config, train_subjects, val_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the first bit of trainin data just to visualise it\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if debug_plots:\n",
    "    for i, batch in enumerate(quadrate_data.train_data):\n",
    "        images = batch[tio.IMAGE][tio.DATA]\n",
    "        masks = batch[tio.LABEL][tio.DATA]\n",
    "        # Images per batch\n",
    "        for j, (image, mask) in enumerate(zip(images, masks)):\n",
    "            fig, _ = images_3d.plot_slices(\n",
    "                image.squeeze().numpy(), mask.squeeze().numpy()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05491904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a model from scratch\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    data_config: data.DataConfig, *, input_model: torch.nn.Module = None\n",
    ") -> tuple[\n",
    "    tuple[torch.nn.Module, list[list[float]], list[list[float]], torch.optim.Optimizer]\n",
    "]:\n",
    "    \"\"\"\n",
    "    Create a model, train and return it\n",
    "\n",
    "    Returns the model, the training losses and the validation losses, and the optimiser\n",
    "\n",
    "    :param input_model: The model to load from disk and fine-tune, if specified\n",
    "\n",
    "    \"\"\"\n",
    "    # Create a model and optimiser\n",
    "    net = model.model(jaw_config[\"model_params\"])\n",
    "\n",
    "    device = jaw_config[\"device\"]\n",
    "    net = net.to(device)\n",
    "    print(f\"Model loaded to {device}\")\n",
    "\n",
    "    optimiser = model.optimiser(jaw_config, net)\n",
    "\n",
    "    # Define loss function\n",
    "    loss = model.lossfn(jaw_config)\n",
    "\n",
    "    train_config = model.TrainingConfig(\n",
    "        device,\n",
    "        jaw_config[\"epochs\"],\n",
    "        torch.optim.lr_scheduler.ExponentialLR(\n",
    "            optimiser, gamma=jaw_config[\"lr_lambda\"]\n",
    "        ),\n",
    "    )\n",
    "    return (\n",
    "        model.train(net, optimiser, loss, data_config, train_config),\n",
    "        optimiser,\n",
    "    )\n",
    "\n",
    "\n",
    "jaw_config[\"epochs\"] = 500\n",
    "(net, train_losses, val_losses), optimiser = train_model(quadrate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the training and validation losses\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from fishjaw.visualisation import training\n",
    "\n",
    "fig = training.plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1461a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot\n",
    "\"\"\"\n",
    "\n",
    "fig = images_3d.plot_inference(\n",
    "    net,\n",
    "    next(iter(val_subjects)),\n",
    "    patch_size=data.get_patch_size(jaw_config),\n",
    "    patch_overlap=(4, 4, 4),\n",
    "    activation=model.activation_name(jaw_config),\n",
    "    batch_size=jaw_config[\"batch_size\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish_jaw_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
